# Experiments on the Divergence among Different Causal Labels

This is the experiment to investigate the divergence between human labels and the labels generated by the original CLEVRER dataset using heuristics on a subset of 50 videos from the CLEVRER dataset. The first method (CLEVRER) uses the heuristic rules defined in the original CLEVRER dataset to predict causal relations between each pair of events. Specifically, if event A happens before event B, and they share at least one object, we say event A is a cause of event B.  The second method (Counterfactual) uses counterfactual intervention to derive the causal relationship. Specifically, we say event A causes event B if event A happens before event B and event B happens even if we remove all relevant objects in event A from the scene (except for the objects in event B). We compare these two methods with human labeled causal relations.

### Usage

- Download the annotations from the [Drive](https://drive.google.com/drive/folders/1agC9_FSf6JqKXUPua_W4wpssx1m0itaN?usp=sharing) and put it inside the `causal_diff_data/` folder.

- Run `python3 causal_diff.py`. 

## Obtain heuristics-generated causal labels: CLEVRER and Counterfactual Intervention 
- To customize annotation data, you can use the simulator and executor in [CLEVRER](https://github.com/chuangg/CLEVRER) to produce CLEVRER heuristic and counterfactual results.
- Download the CLEVRER repo and follow its setup instructions.
- Put `executor_sim.py` and `simulate_annotation.py` under the `executor` folder in the CLEVRER repo. 
- Run `simulate_annotation.py` with customized `idx_list` to get heuristics-generated causal labels.